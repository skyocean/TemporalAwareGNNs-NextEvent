{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f8002-864a-4cf0-847a-c0bad963c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "from DataEncoder import encode_pad_event, encode_pad_sequence, scale_time_differences, encode_label_event, node_time_list, scale_time_differences_fast_fixed, length_stratified_split\n",
    "from GATConv import prepare_data_core_timedif, prepare_data_y, CustomDataset, EarlyStopping, train, evaluate, custom_collate_fn, DualGATModel\n",
    "from GATConv import predict, top_k_accuracy, predict_per_sequence, average_bleu_score, compute_dls_and_exact_match, sequence_level_top_k_accuracy, analyze_sequence_errors, predict_per_sequence_with_probs, sequence_level_top_k_analysis, show_error_sequences\n",
    "import os \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca11d3-4dd7-4cbe-a91d-7ac790aa854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event = pd.read_csv(\"../output/BPI12.csv\")\n",
    "event = pd.read_csv(\"../output/BPI12w.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13i.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13c.csv\")\n",
    "#event = pd.read_csv(\"../output/helpdesk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02056c4-88de-4467-aad9-4d767742e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of sequence\n",
    "shortest_sequence = event.groupby('sequence').size().min()\n",
    "longest_sequence = event.groupby('sequence').size().max()\n",
    "print('shortest_sequence:', shortest_sequence)\n",
    "print('longest_sequence:', longest_sequence)\n",
    "event = event[event.groupby('sequence')['sequence'].transform('size') >= 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54305a87-1a5b-4cc1-ab1d-03482c392d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#core_event = 'event_label' \n",
    "core_event = 'event' # with status\n",
    "case_index = 'sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe611b5-0f83-414b-8e59-e412a4e1d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_encode, y_encode, core_size, output_size, le_event = encode_label_event(event, core_event, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf2a41-dcda-4228-99de-fa9c7dcfea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BPI12 \n",
    "#event['ec1'] = event['ec1'].astype(str) \n",
    "cat_col_event = ['ec1']\n",
    "#BPI17\n",
    "#cat_col_event = ['ec1', 'ec2', 'ec3']\n",
    "#BPI13\n",
    "#cat_col_event = ['ec1', 'ec2', 'ec4', 'ec5']\n",
    "#helpdesk\n",
    "#cat_col_event = ['ec1']\n",
    "num_col_event = []\n",
    "event_encode = encode_pad_event(event, cat_col_event, num_col_event, case_index, cat_mask = True, num_mask = True, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfe00d-52e3-4ad2-82b5-c5f5dc39e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BPI12\n",
    "sequence = event[['sequence','sn1']].groupby('sequence').first()\n",
    "#BPI17\n",
    "#sequence = event[['sequence','sn1', 'sc1', 'sc2']].groupby('sequence').first()\n",
    "#BPI13\n",
    "#sequence = event[['sequence','sc3', 'sc1', 'sc2']].groupby('sequence').first()\n",
    "#sequence = event[['sequence','sc1']].groupby('sequence').first()\n",
    "sequence = sequence.reset_index()\n",
    "#sequence = event.groupby('sequence').apply(lambda x: x.iloc[prefix_size - 1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d6220-b167-4f29-a0e6-f3d6b5bc4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bpi12\n",
    "cat_col_seq = []\n",
    "num_col_seq = ['sn1']\n",
    "#Bpi13\n",
    "#cat_col_seq = ['sc1','sc2','sc3']\n",
    "#num_col_seq = []\n",
    "#helpdesk\n",
    "#cat_col_seq = ['sc1']\n",
    "#num_col_seq = []\n",
    "sequence_encode = encode_pad_sequence(sequence, cat_col_seq, num_col_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164d309-ff41-435d-9466-b1fdc3c36bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_col = 'time'\n",
    "#start_time_col = 'Start Timestamp'\n",
    "scaled_time_diffs = scale_time_differences_fast_fixed(event, sequence, start_time_col, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00292d9-357c-428c-8802-490c500c2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_events = event_encode.shape[1]\n",
    "# Expand sequence features to match the shape of event features\n",
    "sequence_features_expanded = np.expand_dims(sequence_encode, axis=1)\n",
    "sequence_features_expanded = np.repeat(sequence_features_expanded, max_num_events, axis=1)\n",
    "\n",
    "# Combine event and sequence features\n",
    "combined_features = np.concatenate((event_encode, sequence_features_expanded), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ea2d3-8997-428f-9dc2-bb33e6bf3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = event_encode.shape[0]\n",
    "num_event_features = combined_features.shape[2]\n",
    "num_embedding_features = core_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5248460-1b10-4bfb-9874-4744ac8ac929",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_times = node_time_list(event, start_time_col, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcece4a5-3ea5-46ef-b43a-5ca453cb66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph data preparation\n",
    "event_feature_list = prepare_data_core_timedif(combined_features, core_encode, scaled_time_diffs, node_times)\n",
    "y_list = prepare_data_y(combined_features, y_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11909fec-4846-41db-ba2e-886740f03e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stratified sampling over sequence length to preserve distributional characteristics\n",
    "train_indices, test_indices = length_stratified_split(event_feature_list, test_size=0.2, n_bins=10)\n",
    "\n",
    "# Split the data\n",
    "train_event_features = [event_feature_list[i] for i in train_indices]\n",
    "test_event_features = [event_feature_list[i] for i in test_indices]\n",
    "train_y = [y_list[i] for i in train_indices]\n",
    "test_y = [y_list[i] for i in test_indices]\n",
    "\n",
    "# Print statistics\n",
    "train_lengths = [event_feature_list[i].x.shape[0] for i in train_indices]\n",
    "test_lengths = [event_feature_list[i].x.shape[0] for i in test_indices]\n",
    "\n",
    "print(f\"Train set: {len(train_indices)} samples\")\n",
    "print(f\"Train length range: {min(train_lengths)} - {max(train_lengths)}\")\n",
    "print(f\"Train length mean: {np.mean(train_lengths):.2f}\")\n",
    "\n",
    "print(f\"\\nTest set: {len(test_indices)} samples\") \n",
    "print(f\"Test length range: {min(test_lengths)} - {max(test_lengths)}\")\n",
    "print(f\"Test length mean: {np.mean(test_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a45b3-26ae-485b-a4f1-62f564e00daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_event_features, train_y)\n",
    "test_dataset = CustomDataset(test_event_features, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869e30-e0c9-433a-a4d3-32592c2dcabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# parameters\n",
    "embedding_dims = 64\n",
    "gat_hidden_dim_event = 32\n",
    "gat_hidden_dim_embed = 128\n",
    "gat_hidden_dim_concat = 256\n",
    "output_dim = output_size  # vocab size\n",
    "num_heads = 4\n",
    "\n",
    "model = DualGATModel(\n",
    "    num_event_features=num_event_features,\n",
    "    num_embedding_features=num_embedding_features,\n",
    "    embedding_dims=embedding_dims,\n",
    "    gat_hidden_dim_event=gat_hidden_dim_event,\n",
    "    gat_hidden_dim_embed=gat_hidden_dim_embed,\n",
    "    gat_hidden_dim_concat=gat_hidden_dim_concat,\n",
    "    output_dim=output_dim,\n",
    "    num_heads=num_heads\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # ignore padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c648011-a050-4433-8785-bb4b78abee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4dbbc1-c094-4ad9-9f2b-7becff6c586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, delta=0.0)\n",
    "num_epochs = 10\n",
    "\n",
    "# Filepath to save model\n",
    "model_path = \"../output/models/BPI12_timeedge_es.pt\"\n",
    "\n",
    "config = {\n",
    "    'num_event_features': num_event_features,\n",
    "    'num_embedding_features': num_embedding_features,\n",
    "    'embedding_dims': embedding_dims,\n",
    "    'gat_hidden_dim_event': gat_hidden_dim_event,\n",
    "    'gat_hidden_dim_embed': gat_hidden_dim_embed,\n",
    "    'gat_hidden_dim_concat': gat_hidden_dim_concat,\n",
    "    'output_dim': output_dim,\n",
    "    'num_heads': num_heads\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bd52a-c0f1-4b21-a93e-59680805194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels, outs = predict(model, test_loader, device)\n",
    "\n",
    "# Check some predictions\n",
    "for i in range(10):\n",
    "    print(f\"Predicted: {preds[i].item()} | Actual: {labels[i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aac788-73d6-4be9-853b-75397c47ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = top_k_accuracy(outs, labels, k=1)\n",
    "top3 = top_k_accuracy(outs, labels, k=3)\n",
    "top5 = top_k_accuracy(outs, labels, k=5)\n",
    "\n",
    "print(f\"Top-1 Acc: {top1:.4f} | Top-3 Acc: {top3:.4f} | Top-5 Acc: {top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9739dfc-3f4e-43c1-8467-66148529985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_seq, labels_seq = predict_per_sequence(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f3294-ff19-4ecb-a449-b2cb9de46f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = average_bleu_score(preds_seq, labels_seq)\n",
    "print(f\"Average BLEU Score: {bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee1d8a-74d7-4686-a5ab-c74f64833ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dls, exact_acc = compute_dls_and_exact_match(preds_seq, labels_seq)\n",
    "print(f\"Damerau-Levenshtein Similarity (avg): {avg_dls:.4f}\")\n",
    "print(f\"Exact Match Accuracy: {exact_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7106b5e-09c8-4d3d-9e15-8d83d633faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "seq_top3_acc = sequence_level_top_k_accuracy(model, test_loader, device, k=3)\n",
    "print(f\"Sequence-Level Top-3 Accuracy: {seq_top3_acc:.4f}\")\n",
    "\n",
    "seq_top5_acc = sequence_level_top_k_accuracy(model, test_loader, device, k=5)\n",
    "print(f\"Sequence-Level Top-5 Accuracy: {seq_top5_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b60583-02c9-4ed4-bb33-1e6105b5bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "pos_errors, error_types, seq_stats = analyze_sequence_errors(model, test_loader, device, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9e201-8367-4975-b40e-f8a922f41825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get predictions with probabilities\n",
    "all_preds, all_labels, all_topk = predict_per_sequence_with_probs(model, test_loader, device, k=3)\n",
    "\n",
    "# Then analyze sequence-level top-k accuracy\n",
    "topk_acc, error_stats = sequence_level_top_k_analysis(all_topk, all_labels)\n",
    "\n",
    "print(f\"Sequence-Level Top-3 Accuracy: {topk_acc:.4f}\")\n",
    "print(\"\\nError Analysis:\")\n",
    "print(f\"- Most error-prone positions: {error_stats['position_errors']}\")\n",
    "print(f\"- Top prediction mistakes: {error_stats['top_errors']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9ffc9-3820-4e43-8f64-813c43afe12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_error_sequences(all_topk, all_labels, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd910c81-01f0-4756-a979-eb3390c995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "unique_true = np.unique(labels.cpu().numpy())\n",
    "unique_preds = np.unique(preds.cpu().numpy())\n",
    "\n",
    "print(\"Classes in true labels:\", unique_true)\n",
    "print(\"Classes in predictions:\", unique_preds)\n",
    "print(\"Missing classes:\", set(unique_true) - set(unique_preds))\n",
    "\n",
    "actual_classes = np.union1d(unique_true, unique_preds)\n",
    "report = classification_report(\n",
    "    labels.cpu().numpy(),\n",
    "    preds.cpu().numpy(),\n",
    "    target_names=[f\"Class_{i}\" for i in actual_classes] ,\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35987c30-19b2-43ad-8f4c-b42cd694045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model state\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# Rebuild the model using the same config\n",
    "model = DualGATModel(\n",
    "    num_event_features=config['num_event_features'],\n",
    "    num_embedding_features=config['num_embedding_features'],\n",
    "    embedding_dims=config['embedding_dims'],\n",
    "    gat_hidden_dim_event=config['gat_hidden_dim_event'],\n",
    "    gat_hidden_dim_embed=config['gat_hidden_dim_embed'],\n",
    "    gat_hidden_dim_concat=config['gat_hidden_dim_concat'],\n",
    "    output_dim=config['output_dim'],\n",
    "    num_heads=config['num_heads']\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Rebuild optimizer (if needed)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Recover attention and event IDs\n",
    "start_epoch = checkpoint['epoch'] + 1 \n",
    "\n",
    "for epoch in range(start_epoch, 10):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7ab69-f2c2-48a6-b4fd-9a4c7f190ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
