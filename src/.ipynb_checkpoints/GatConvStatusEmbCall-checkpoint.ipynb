{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f8002-864a-4cf0-847a-c0bad963c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader \n",
    "from sklearn.model_selection import train_test_split\n",
    "from DataEncoder import encode_pad_event, encode_pad_sequence, scale_time_differences, encode_label_event, node_time_list, event_transition_edge, scale_time_differences_fast_fixed, length_stratified_split\n",
    "from GATConvStatusEmb import prepare_data_core_2edges, prepare_data_y, CustomDataset, EarlyStopping, train, evaluate, custom_collate_fn, DualGAT2EdgesModel\n",
    "from GATConvStatusEmb import predict, top_k_accuracy, predict_per_sequence, average_bleu_score, compute_dls_and_exact_match, sequence_level_top_k_accuracy, analyze_sequence_errors, predict_per_sequence_with_probs, sequence_level_top_k_analysis, show_error_sequences\n",
    "import os \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca11d3-4dd7-4cbe-a91d-7ac790aa854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event = pd.read_csv(\"../output/BPI12.csv\")\n",
    "event = pd.read_csv(\"../output/BPI12w.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13i.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13c.csv\")\n",
    "#event = pd.read_csv(\"../output/helpdesk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02056c4-88de-4467-aad9-4d767742e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of sequence\n",
    "shortest_sequence = event.groupby('sequence').size().min()\n",
    "longest_sequence = event.groupby('sequence').size().max()\n",
    "print('shortest_sequence:', shortest_sequence)\n",
    "print('longest_sequence:', longest_sequence)\n",
    "event = event[event.groupby('sequence')['sequence'].transform('size') >= 2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54305a87-1a5b-4cc1-ab1d-03482c392d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#core_event = 'event_label'\n",
    "core_event = 'event' #substatus\n",
    "case_index = 'sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe611b5-0f83-414b-8e59-e412a4e1d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_encode, y_encode, core_size, output_size, le_event = encode_label_event(event, core_event, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf2a41-dcda-4228-99de-fa9c7dcfea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event['ec1'] = event['ec1'].astype(str) \n",
    "cat_col_event = ['ec1']\n",
    "num_col_event = []\n",
    "#Bpi13\n",
    "#cat_col_event = ['ec1', 'ec2', 'ec4', 'ec5']\n",
    "#num_col_seq = []\n",
    "#helpdesk\n",
    "#cat_col_event = ['ec1']\n",
    "#num_col_event = []\n",
    "event_encode = encode_pad_event(event, cat_col_event, num_col_event, case_index, cat_mask = True, num_mask = True, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cfe00d-52e3-4ad2-82b5-c5f5dc39e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = event[['sequence','sn1']].groupby('sequence').first()\n",
    "#BPI13\n",
    "#sequence = event[['sequence','sc3', 'sc1', 'sc2']].groupby('sequence').first()\n",
    "#sequence = event[['sequence','sc1']].groupby('sequence').first()\n",
    "sequence = sequence.reset_index()\n",
    "#sequence = event.groupby('sequence').apply(lambda x: x.iloc[prefix_size - 1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d6220-b167-4f29-a0e6-f3d6b5bc4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_seq = []\n",
    "num_col_seq = ['sn1']\n",
    "#BPI13\n",
    "#cat_col_seq = ['sc1','sc2','sc3']\n",
    "#num_col_seq = []\n",
    "#helpdesk\n",
    "#cat_col_seq = ['sc1']\n",
    "#num_col_seq = []\n",
    "sequence_encode = encode_pad_sequence(sequence, cat_col_seq, num_col_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3ff4b-9b8a-40f4-bdf2-6f701d89b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = 'event'\n",
    "event_trans_edge, le_edge, trans_size = event_transition_edge(event, sequence, status, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164d309-ff41-435d-9466-b1fdc3c36bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_col = 'time'\n",
    "#start_time_col = 'Start Timestamp'\n",
    "scaled_time_diffs = scale_time_differences_fast_fixed(event, sequence, start_time_col, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00292d9-357c-428c-8802-490c500c2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_events = event_encode.shape[1]\n",
    "# Expand sequence features to match the shape of event features\n",
    "sequence_features_expanded = np.expand_dims(sequence_encode, axis=1)\n",
    "sequence_features_expanded = np.repeat(sequence_features_expanded, max_num_events, axis=1)\n",
    "\n",
    "# Combine event and sequence features\n",
    "combined_features = np.concatenate((event_encode, sequence_features_expanded), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758ea2d3-8997-428f-9dc2-bb33e6bf3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = event_encode.shape[0]\n",
    "num_event_features = combined_features.shape[2]\n",
    "num_embedding_features = core_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcece4a5-3ea5-46ef-b43a-5ca453cb66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_feature_list = prepare_data_core_2edges(combined_features, core_encode, scaled_time_diffs, event_trans_edge)\n",
    "y_list = prepare_data_y(combined_features, y_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3abe0-db3a-4f8f-84ed-d2d46375eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use stratified sampling over sequence length to preserve distributional characteristics\n",
    "train_indices, test_indices = length_stratified_split(event_feature_list, test_size=0.2, n_bins=10)\n",
    "\n",
    "# Split the data\n",
    "train_event_features = [event_feature_list[i] for i in train_indices]\n",
    "test_event_features = [event_feature_list[i] for i in test_indices]\n",
    "train_y = [y_list[i] for i in train_indices]\n",
    "test_y = [y_list[i] for i in test_indices]\n",
    "\n",
    "# Print statistics\n",
    "train_lengths = [event_feature_list[i].x.shape[0] for i in train_indices]\n",
    "test_lengths = [event_feature_list[i].x.shape[0] for i in test_indices]\n",
    "\n",
    "print(f\"Train set: {len(train_indices)} samples\")\n",
    "print(f\"Train length range: {min(train_lengths)} - {max(train_lengths)}\")\n",
    "print(f\"Train length mean: {np.mean(train_lengths):.2f}\")\n",
    "\n",
    "print(f\"\\nTest set: {len(test_indices)} samples\") \n",
    "print(f\"Test length range: {min(test_lengths)} - {max(test_lengths)}\")\n",
    "print(f\"Test length mean: {np.mean(test_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a45b3-26ae-485b-a4f1-62f564e00daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_event_features, train_y)\n",
    "test_dataset = CustomDataset(test_event_features, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7acb3-687a-4e3a-92e5-f56dac309a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# parameters\n",
    "embedding_dims = 64\n",
    "gat_hidden_dim_event = 32\n",
    "gat_hidden_dim_embed = 128\n",
    "gat_hidden_dim_concat = 256\n",
    "output_dim = output_size  # vocab size\n",
    "num_heads = 4\n",
    "num_edge_types = trans_size\n",
    "edge_type_dim = 32\n",
    "\n",
    "model = DualGAT2EdgesModel(\n",
    "    num_event_features=num_event_features,\n",
    "    num_embedding_features=num_embedding_features,\n",
    "    embedding_dims=embedding_dims,\n",
    "    gat_hidden_dim_event=gat_hidden_dim_event,\n",
    "    gat_hidden_dim_embed=gat_hidden_dim_embed,\n",
    "    gat_hidden_dim_concat=gat_hidden_dim_concat,\n",
    "    output_dim=output_dim,\n",
    "    num_heads=num_heads,\n",
    "    num_edge_types=num_edge_types,\n",
    "    edge_type_dim=edge_type_dim\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)  # ignore padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8c0d7-549a-4633-a7b4-ee1fe02449ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff89da-7864-4a00-9f0d-2a62ac52c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=3, delta=0.0)\n",
    "num_epochs = 10\n",
    "\n",
    "# Filepath to save model\n",
    "model_path = \"../output/models/BPI12w_transedge_es.pt\"\n",
    "\n",
    "config = {\n",
    "    'num_event_features': num_event_features,\n",
    "    'num_embedding_features': num_embedding_features,\n",
    "    'embedding_dims': embedding_dims,\n",
    "    'gat_hidden_dim_event': gat_hidden_dim_event,\n",
    "    'gat_hidden_dim_embed': gat_hidden_dim_embed,\n",
    "    'gat_hidden_dim_concat': gat_hidden_dim_concat,\n",
    "    'output_dim': output_dim,\n",
    "    'num_heads': num_heads,\n",
    "    'num_edge_types': num_edge_types,\n",
    "    'edge_type_dim': edge_type_dim\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7106b5e-09c8-4d3d-9e15-8d83d633faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels, outs = predict(model, test_loader, device)\n",
    "\n",
    "# Check some predictions\n",
    "for i in range(10):\n",
    "    print(f\"Predicted: {preds[i].item()} | Actual: {labels[i].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1451742-0d69-4318-86db-8a73b3c7a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = top_k_accuracy(outs, labels, k=1)\n",
    "top3 = top_k_accuracy(outs, labels, k=3)\n",
    "top5 = top_k_accuracy(outs, labels, k=5)\n",
    "\n",
    "print(f\"Top-1 Acc: {top1:.4f} | Top-3 Acc: {top3:.4f} | Top-5 Acc: {top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b1a7a-d5ba-4558-8db5-e092fed09835",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_seq, labels_seq = predict_per_sequence(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef76a5f-9d2c-4b73-98da-b9eb36969d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = average_bleu_score(preds_seq, labels_seq)\n",
    "print(f\"Average BLEU Score: {bleu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d889145-de6a-4113-a912-663e543d8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_dls, exact_acc = compute_dls_and_exact_match(preds_seq, labels_seq)\n",
    "print(f\"Damerau-Levenshtein Similarity (avg): {avg_dls:.4f}\")\n",
    "print(f\"Exact Match Accuracy: {exact_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac929b-1214-465d-a5e1-7bd30bb3dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "seq_top3_acc = sequence_level_top_k_accuracy(model, test_loader, device, k=3)\n",
    "print(f\"Sequence-Level Top-3 Accuracy: {seq_top3_acc:.4f}\")\n",
    "seq_top5_acc = sequence_level_top_k_accuracy(model, test_loader, device, k=5)\n",
    "print(f\"Sequence-Level Top-5 Accuracy: {seq_top5_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23262d33-f7e0-4abd-ab85-7be40843eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "pos_errors, error_types, seq_stats = analyze_sequence_errors(model, test_loader, device, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46192a-ba61-440b-98e7-f374f780fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get predictions with probabilities\n",
    "all_preds, all_labels, all_topk = predict_per_sequence_with_probs(model, test_loader, device, k=3)\n",
    "\n",
    "# Then analyze sequence-level top-k accuracy\n",
    "topk_acc, error_stats = sequence_level_top_k_analysis(all_topk, all_labels)\n",
    "\n",
    "print(f\"Sequence-Level Top-3 Accuracy: {topk_acc:.4f}\")\n",
    "print(\"\\nError Analysis:\")\n",
    "print(f\"- Most error-prone positions: {error_stats['position_errors']}\")\n",
    "print(f\"- Top prediction mistakes: {error_stats['top_errors']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39191355-5054-4731-a14e-040e3284b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_error_sequences(all_topk, all_labels, num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143014e6-f283-4cc8-be3e-2d5c8ac5dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "unique_true = np.unique(labels.cpu().numpy())\n",
    "unique_preds = np.unique(preds.cpu().numpy())\n",
    "\n",
    "print(\"Classes in true labels:\", unique_true)\n",
    "print(\"Classes in predictions:\", unique_preds)\n",
    "print(\"Missing classes:\", set(unique_true) - set(unique_preds))\n",
    "\n",
    "actual_classes = np.union1d(unique_true, unique_preds)\n",
    "report = classification_report(\n",
    "    labels.cpu().numpy(),\n",
    "    preds.cpu().numpy(),\n",
    "    target_names=[f\"Class_{i}\" for i in actual_classes] ,\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e6fc2-effd-4bb5-b189-7fb7df4c4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model state\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# Rebuild the model using the same config\n",
    "model = DualGAT2EdgesModel(\n",
    "    num_event_features=config['num_event_features'],\n",
    "    num_embedding_features=config['num_embedding_features'],\n",
    "    embedding_dims=config['embedding_dims'],\n",
    "    gat_hidden_dim_event=config['gat_hidden_dim_event'],\n",
    "    gat_hidden_dim_embed=config['gat_hidden_dim_embed'],\n",
    "    gat_hidden_dim_concat=config['gat_hidden_dim_concat'],\n",
    "    output_dim=config['output_dim'],\n",
    "    num_heads=config['num_heads'],\n",
    "    num_edge_types=config['num_edge_types'],\n",
    "    edge_type_dim=config['edge_type_dim']\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Rebuild optimizer (if needed)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Recover attention and event IDs\n",
    "start_epoch = checkpoint['epoch'] + 1 \n",
    "\n",
    "for epoch in range(start_epoch, 10):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094c49a-cc6f-45ed-ac29-857e4769a355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
