{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c67f2c-2d31-4f40-9cb3-e3ecd561df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from DataEncoder import encode_event_prefix_label, encode_pad_sequence, scale_time_differences, scale_time_differences_fast_fixed\n",
    "from PrefixEmbeddingGCN import prepare_data, CustomDataset,  train, evaluate, EarlyStopping, custom_collate, PrefixGCNClassifier, f1_eva, get_misclassified_samples, cluster_errors\n",
    "import os \n",
    "import shutil\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe997fd5-5eff-4777-9575-f798a55df381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event = pd.read_csv(\"../output/BPI12.csv\")\n",
    "event = pd.read_csv(\"../output/BPI12w.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13i.csv\")\n",
    "#event = pd.read_csv(\"../output/BPI13c.csv\")\n",
    "#event = pd.read_csv(\"../output/helpdesk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd8a0f-487e-4093-b496-ec286449c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of sequence\n",
    "shortest_sequence = event.groupby('sequence').size().min()\n",
    "longest_sequence = event.groupby('sequence').size().max()\n",
    "\n",
    "print('shortest_sequence:', shortest_sequence)\n",
    "print('longest_sequence:', longest_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75fed6f-e358-4dbc-a961-159c3f2f0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prefix size \n",
    "prefix_size = 10\n",
    "# Keep only sequence that have at least `prefix_size` members\n",
    "event = event[event.groupby('sequence')['sequence'].transform('size') >= prefix_size].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4800e17e-d482-4e99-ac44-ce4a8d919c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BPI13i\n",
    "#cat_col_event = ['ec1', 'ec4']\n",
    "#BPi12\n",
    "event['ec1'] = event['ec1'].astype(str) \n",
    "cat_col_event = ['ec1']\n",
    "#cat_col_event = []\n",
    "#num_col_event = []\n",
    "#helpdesk\n",
    "#cat_col_event = ['ec1']\n",
    "num_col_event = []\n",
    "core_event = 'event'\n",
    "case_index = 'sequence'\n",
    "text_encode, event_encode, y_encode, text_size, output_dim = encode_event_prefix_label(event, core_event, cat_col_event, num_col_event, case_index, prefix_size, cat_mask=False, num_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba21c5-e7e1-4350-b32d-fefee1f397e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = event.groupby('sequence').apply(lambda x: x.iloc[prefix_size - 1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc7330-066c-48cc-af00-0d6f5bc4b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_seq = []\n",
    "num_col_seq = ['sn1']\n",
    "#BPI13c\n",
    "#cat_col_seq = ['sc2','sc3']\n",
    "#num_col_seq = []\n",
    "#helpdesk\n",
    "#cat_col_seq = ['sc1']\n",
    "#num_col_seq = []\n",
    "sequence_encode = encode_pad_sequence(sequence, cat_col_seq, num_col_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e56ee-add3-4756-863d-f938fa889b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_col = 'time'\n",
    "#start_time_col = 'StartTime'\n",
    "scaled_time_diffs = scale_time_differences_fast_fixed(event, sequence, start_time_col, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461683d-e0eb-4c3f-80a6-b24320092496",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = event_encode.shape[0]\n",
    "max_num_events = prefix_size\n",
    "num_event_features = event_encode.shape[2]\n",
    "num_sequence_features = sequence_encode.shape[1]\n",
    "num_embedding_features = output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6c932-c9bb-43d2-a633-d8c9b91a4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_feature_list = prepare_data(event_encode, text_encode, scaled_time_diffs)\n",
    "sequence_features = torch.tensor(sequence_encode, dtype=torch.float)\n",
    "y_encode = torch.tensor(y_encode, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0770bd-babf-45a7-bf15-f1f35de1c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each class\n",
    "class_counts = Counter(y_encode.numpy())\n",
    "print(\"Class distribution:\", class_counts)\n",
    "\n",
    "# Find classes with only one sample\n",
    "single_sample_classes = [cls for cls, count in class_counts.items() if count == 1]\n",
    "print(\"Classes with only 1 sample:\", single_sample_classes)\n",
    "\n",
    "# Create mask to keep only classes with 2+ samples\n",
    "mask = np.array([y not in single_sample_classes for y in y_encode.numpy()])\n",
    "\n",
    "# Filter your data\n",
    "filtered_indices = np.where(mask)[0]\n",
    "filtered_event_features = [event_feature_list[i] for i in filtered_indices]\n",
    "filtered_sequence_features = sequence_features[filtered_indices]\n",
    "filtered_y = y_encode[filtered_indices]\n",
    "\n",
    "print(f\"Original samples: {len(event_feature_list)}\")\n",
    "print(f\"Filtered samples: {len(filtered_event_features)}\")\n",
    "print(f\"Removed {len(event_feature_list) - len(filtered_event_features)} samples\")\n",
    "\n",
    "# Now perform the split with filtered data\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(filtered_event_features)), \n",
    "    test_size=0.2, \n",
    "    stratify=filtered_y.numpy(), \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split the filtered data\n",
    "train_event_features = [filtered_event_features[i] for i in train_indices]\n",
    "test_event_features = [filtered_event_features[i] for i in test_indices]\n",
    "train_sequence_features = filtered_sequence_features[train_indices]\n",
    "test_sequence_features = filtered_sequence_features[test_indices]\n",
    "train_y = filtered_y[train_indices]\n",
    "test_y = filtered_y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1855c2-8e5d-43c0-bac3-e47ff98b73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_event_features, train_sequence_features, train_y)\n",
    "test_dataset = CustomDataset(test_event_features, test_sequence_features, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b75f0f4-777a-4aa7-8e2c-b47a0bdcaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyperparameters\n",
    "num_event_features = num_event_features\n",
    "gcn_hidden_dims = 32\n",
    "num_embedding_features = num_embedding_features\n",
    "embedding_dims = 16\n",
    "gcn_hidden_dims_embedding = 32\n",
    "gcn_hidden_dims_concat = 64\n",
    "num_sequence_features = num_sequence_features\n",
    "fc_hidden_dims = 32\n",
    "fc_hidden_dims_concat = 64\n",
    "output_dim = output_dim\n",
    "\n",
    "model = PrefixGCNClassifier(num_event_features, \n",
    "                            gcn_hidden_dims,\n",
    "                            num_embedding_features, \n",
    "                            embedding_dims,\n",
    "                            gcn_hidden_dims_embedding, \n",
    "                            gcn_hidden_dims_concat,\n",
    "                            num_sequence_features, \n",
    "                            fc_hidden_dims,\n",
    "                            fc_hidden_dims_concat, \n",
    "                            output_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05534bcc-8a2f-404e-a762-8654772fdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader with the loaded batch size\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, delta=0.0)\n",
    "\n",
    "# Filepath to save model\n",
    "model_path = \"../output/models/1BPI13i_prefix15_es.pt\"\n",
    "\n",
    "config = {\n",
    "    'num_event_features': num_event_features,\n",
    "    'gcn_hidden_dims': gcn_hidden_dims,\n",
    "    'num_embedding_features': num_embedding_features,\n",
    "    'embedding_dims': embedding_dims,\n",
    "    'gcn_hidden_dims_embedding': gcn_hidden_dims_embedding,\n",
    "    'gcn_hidden_dims_concat': gcn_hidden_dims_concat,\n",
    "    'num_sequence_features': num_sequence_features,\n",
    "    'fc_hidden_dims':fc_hidden_dims,\n",
    "    'fc_hidden_dims_concat':fc_hidden_dims_concat,\n",
    "    'output_dim': output_dim\n",
    "}\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        best_model = model\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ede79-c3c3-4eb3-b9b9-e2655626e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final evaluation to get predictions and labels\n",
    "model = best_model\n",
    "class_report, top3_acc = f1_eva(model, test_loader, device, k=3)\n",
    "_, top5_acc = f1_eva(model, test_loader, device, k=5)\n",
    "\n",
    "print(f\"Top-3 Accuracy: {top3_acc:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (with F1 scores for each class):\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81192328-d689-44df-9a50-525fbdc6933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = get_misclassified_samples(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c3731-695c-4528-ac55-3c46b1c14fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different feature types and methods\n",
    "num_clusters = 10\n",
    "cluster_ids = cluster_errors(errors, num_clusters, use='event_feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0518a-7357-40aa-b201-45c0dec70067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running cluster_errors()\n",
    "num_clusters = 10\n",
    "for cluster_id in range(num_clusters):\n",
    "    cluster_samples = [e for e, c in zip(errors, cluster_ids) if c == cluster_id]\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_samples)} samples):\")\n",
    "    \n",
    "    # Top error patterns\n",
    "    from collections import Counter\n",
    "    print(\"Common mistakes:\", Counter((e['label'], e['pred']) for e in cluster_samples).most_common(3))\n",
    "    \n",
    "    # Average feature vector\n",
    "    avg_features = np.mean([e['event_feats'] for e in cluster_samples], axis=0)\n",
    "    print(\"Most salient features:\", np.argsort(avg_features)[-5:])  # Top 5 influential features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf7ae0-b502-4a2c-8ff4-b5707eb67b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "config = checkpoint['config']\n",
    "\n",
    "# Rebuild the model using the same config\n",
    "model = PrefixGCNClassifier(\n",
    "    num_event_features=config['num_event_features'],\n",
    "    gcn_hidden_dims=config['gcn_hidden_dims'],\n",
    "    num_embedding_features=config['num_embedding_features'],\n",
    "    embedding_dims=config['embedding_dims'],\n",
    "    gcn_hidden_dims_embedding=config['gcn_hidden_dims_embedding'],\n",
    "    gcn_hidden_dims_concat=config['gcn_hidden_dims_concat'],\n",
    "    num_sequence_features=config['num_sequence_features'],\n",
    "    fc_hidden_dims=config['fc_hidden_dims'],\n",
    "    fc_hidden_dims_concat=config['fc_hidden_dims_concat'],\n",
    "    output_dim=config['output_dim']\n",
    ")\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Rebuild optimizer (if needed)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Create DataLoader with the loaded batch size\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, delta=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5365e-fa4c-4896-85ea-b15bf72eeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = checkpoint['epoch'] + 1 \n",
    "\n",
    "for epoch in range(start_epoch, 10):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} Acc: {test_acc:.4f}\")\n",
    "    \n",
    "    if early_stopping(test_loss):\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    if early_stopping.best_loss_updated:\n",
    "        print(f\"New best model at epoch {epoch+1}, saving to {model_path}\")\n",
    "        best_model_saved = True\n",
    "         # Save state dict and config\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)\n",
    "        \n",
    "if not early_stopping.early_stop and not best_model_saved:\n",
    "        print(\"Training completed without early stopping. Saving final model.\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'test_loss': test_loss,\n",
    "            'test_acc': test_acc,\n",
    "            'config': config\n",
    "        }, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584b9ec-5736-472d-9387-b10b75735118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
